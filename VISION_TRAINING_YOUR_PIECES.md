# Training Vision AI with YOUR Chess Pieces

> **Best Practice:** Train on YOUR specific chess pieces for 98-99% accuracy

## Why Train on Your Pieces Only?

**Your Chess Mover Machine = Fixed Environment:**
- âœ… Same chess set every time
- âœ… Same board position
- âœ… Same camera angle
- âœ… Same lighting setup

**Result: Perfect for specialized model!**
- 98-99% accuracy on YOUR board
- Faster training (1-2 hours vs 6-8 hours)
- Fewer images needed (1,200 vs 10,000+)
- More reliable for automated gameplay

**Don't waste time on chess sets you don't own yet!**

---

## Quick Start: Record Your Chess Pieces

### What You Need
- Your chess set
- Webcam or phone camera
- Good lighting (LED desk lamp works great)
- 15 minutes of your time

### Recording Setup

**Lighting:**
- Use consistent bright lighting
- Avoid harsh shadows
- LED desk lamp pointed at board works perfectly

**Camera Position:**
- Position camera overhead (30-40cm above board)
- Ensure entire square is visible
- Keep camera steady (tripod or stack of books)

### Recording Process (15 minutes total)

**For each of the 12 piece types:**

```bash
cd "C:\Users\David\Documents\GitHub\Chess Mover Machine"

# White pieces (30 seconds each)
python vision/collect_training_data.py --mode webcam --piece pawn --color white --duration 30
python vision/collect_training_data.py --mode webcam --piece knight --color white --duration 30
python vision/collect_training_data.py --mode webcam --piece bishop --color white --duration 30
python vision/collect_training_data.py --mode webcam --piece rook --color white --duration 30
python vision/collect_training_data.py --mode webcam --piece queen --color white --duration 30
python vision/collect_training_data.py --mode webcam --piece king --color white --duration 30

# Black pieces (30 seconds each)
python vision/collect_training_data.py --mode webcam --piece pawn --color black --duration 30
python vision/collect_training_data.py --mode webcam --piece knight --color black --duration 30
python vision/collect_training_data.py --mode webcam --piece bishop --color black --duration 30
python vision/collect_training_data.py --mode webcam --piece rook --color black --duration 30
python vision/collect_training_data.py --mode webcam --piece queen --color black --duration 30
python vision/collect_training_data.py --mode webcam --piece king --color black --duration 30
```

**What to do during each 30-second recording:**
1. Place piece on a light square
2. Slowly rotate piece 360Â° (takes ~10 seconds)
3. Move piece to a dark square
4. Slowly rotate piece 360Â° again (takes ~10 seconds)
5. Move to different light square
6. Rotate one more time (~10 seconds)

**Script automatically extracts ~90 images from each video!**

### Organize Dataset (1 minute)

After recording all 12 pieces:

```bash
# Organize into train/val split (80/20)
python vision/collect_training_data.py --organize

# This creates:
# datasets/my_chess_set/
# â”œâ”€â”€ train/ (880 images)
# â””â”€â”€ val/ (220 images)
```

### Train Model (1-2 hours on your RTX 4080 SUPER)

```bash
python vision/simple_train.py
```

When prompted for dataset path, enter:
```
datasets/my_chess_set/data.yaml
```

The training will:
- Load YOLOv8 nano model (fastest, 3MB)
- Train for 50 epochs on your GPU
- Take 1-2 hours
- Save best model to: `runs/chess_training/chess_detector/weights/best.pt`
- Export to ONNX: `runs/chess_training/chess_detector/weights/best.onnx`

### Expected Results

**Accuracy:**
- Overall: 98-99%
- Per-piece: >98% for each piece type
- Errors: <1% misclassifications

**Speed:**
- Desktop GPU: 200+ FPS
- Raspberry Pi with Hailo: 40-80 FPS
- Raspberry Pi without Hailo: 2-5 FPS

### Deploy to Raspberry Pi (when camera arrives)

1. **Copy model to Pi:**
   ```bash
   scp runs/chess_training/chess_detector/weights/best.onnx pi@raspberrypi:/home/pi/chess_mover/models/
   ```

2. **Convert to Hailo format (on Pi):**
   ```bash
   ssh pi@raspberrypi
   cd /home/pi/chess_mover
   hailo model-zoo compile --ckpt models/best.onnx --hw-arch hailo8l --performance
   ```

3. **Test live:**
   ```bash
   python vision/test_live.py --model models/best.hef
   ```

---

## Tips for Best Results

### Recording Quality

**Do:**
- âœ… Keep lighting consistent throughout all recordings
- âœ… Rotate pieces slowly and smoothly
- âœ… Record on both light and dark squares
- âœ… Keep camera position fixed for all pieces
- âœ… Clean your pieces (fingerprints can confuse AI)

**Don't:**
- âŒ Record in different rooms with different lighting
- âŒ Rush the rotation (too fast = motion blur)
- âŒ Only record on one square color
- âŒ Move camera between recordings
- âŒ Record with dirty/smudged pieces

### Common Issues

**Problem: Model confuses knights and bishops**
- Solution: Record more images with slight camera angle (not just straight overhead)

**Problem: Model struggles with light vs dark squares**
- Solution: Ensure 50/50 split between light and dark squares during recording

**Problem: Low accuracy (<95%)**
- Solution:
  1. Check lighting consistency
  2. Record 60-second videos instead of 30 seconds
  3. Clean pieces and try again
  4. Ensure camera isn't moving during recording

---

## When to Retrain

### âœ… Retrain if:
- You get a new chess set
- You move machine to room with very different lighting
- Accuracy drops below 95%
- You modify camera position significantly

### âŒ Don't retrain for:
- Different board positions (model handles this)
- Playing different games
- Normal lighting variations (model is robust to minor changes)
- Moving board a few inches

---

## Alternative: Phone Camera

If webcam quality is poor, use your phone:

1. **Record videos on phone:**
   - 30 seconds per piece
   - Rotate slowly
   - Light and dark squares
   - Save as MP4

2. **Transfer to computer:**
   ```bash
   # Copy videos to: C:\Users\David\Videos\chess_pieces\
   ```

3. **Extract frames:**
   ```bash
   python vision/collect_training_data.py \
       --mode video \
       --video "C:\Users\David\Videos\chess_pieces\white_pawn.mp4" \
       --piece pawn \
       --color white \
       --interval 10 \
       --max-images 200
   ```

4. **Repeat for all 12 pieces, then organize and train as above**

---

## Cost-Benefit Analysis

**Training on YOUR pieces:**
- Time: 15 min recording + 1-2 hours training = **2.25 hours total**
- Accuracy: **98-99%**
- Images needed: **1,200**
- Maintenance: Only retrain if chess set changes

**Training on online datasets + YOUR pieces (hybrid):**
- Time: 30 min download + 2 hours training + 15 min recording + 30 min fine-tune = **3.25 hours**
- Accuracy: **98-99%** (same as above)
- Images needed: **5,000-10,000+**
- Benefit: Slightly better generalization if you swap sets frequently

**Recommendation for you:**
Just train on YOUR pieces! You're not swapping chess sets, so the hybrid approach adds 1 hour of work for no benefit.

---

## Summary

**Your workflow:**
1. âœ… Record 30-second videos of YOUR 12 piece types (15 minutes)
2. âœ… Organize dataset (1 minute)
3. âœ… Train model on RTX 4080 SUPER (1-2 hours)
4. âœ… Deploy to Raspberry Pi when camera arrives
5. âœ… Enjoy 98-99% accuracy on YOUR board!

**Don't bother with:**
- âŒ Downloading online datasets
- âŒ Training on chess sets you don't own
- âŒ Hybrid approaches
- âŒ Over-complicating the process

**Result:** Specialized AI that's perfect for YOUR exact setup! ðŸŽ¯
